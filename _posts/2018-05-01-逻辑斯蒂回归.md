---
layout:     post       # 使用的布局（不需要改）
title:      逻辑斯蒂回归  # 标题 
subtitle:    #副标题
date:       2018-05-01 # 时间
author:     xyangk  # 作者
header-img: img/post-bg-lr.png #这篇文章标题背景图片
catalog: true  # 是否归档
tags: #标签
    - 逻辑斯蒂回归
    - LR
---

### 逻辑斯蒂回归

#### Logistic Regression

- sigmoid函数：

  $g(z)=\frac{e^{z}}{1+e^{z}}$函数图像如下，令  $z=\theta^Tx$

  $g(x)=\frac{e^{\theta^Tx}}{1+e^{\theta^Tx}}$

  ![sigmoid](https://user-images.githubusercontent.com/9495054/53283635-5f901680-3784-11e9-8232-ef87da0f819b.png)

  ​

$\theta^Tx$的结果是整个实数域，通过sigmoid函数可以映射到区间[0,1]，得到概率

> 可以把分类问题理解成事件发生的概率$p$，比如对邮件分类来说更有可能属于哪一类，分到哪一类的概率最大。既然是概率，值介于0到1，而我么最初的线性分类器$\theta^Tx$的值域是整个实数域，所以需要进行变换。
>
> - 从实数域映射到$[0,1]$。 令$z=\theta^Tx$, 其结果是任意实数，$f=e^z$可以将$z$映射到正实数域$(0,\infty)$,再从正实数域映射到$[0,1]$可以用$g=\frac{f}{1+f}$，函数图像如下：
>
>   ![exp1](https://user-images.githubusercontent.com/9495054/53283652-7a628b00-3784-11e9-9125-651f0a48b183.png)

> - 从概率$[0,1]$映射到实数域即$\theta^Tx$。知道概率$p$，几率(odds)表示事件发生的概率和该事件不发生的概率的比值，$odds=\frac{p}{1-p}$，可以转换到正实数域$[0,\infty]$，再使用log函数$log(odds)=log(\frac{p}{1-p})$转换到实数域$(-\infty,\infty)$，函数图像分别如下：
>
>   ![odds](https://user-images.githubusercontent.com/9495054/53283655-864e4d00-3784-11e9-9600-000f297f3607.png)
>
>   通过上面的转换可以将线性分类器和概率值联系起来，即$log(\frac{p}{1-p})=\theta^Tx$，可以求出来$p=\frac{e^{\theta^Tx}}{1+e^{\theta^Tx}}$，得到sigmoid函数。 

- 最大似然估计

  现在知道了
  
  $P(y=1\|x)=\frac{e^{\theta^Tx}}{1+e^{\theta^Tx}}=g(x)$，$P(y=0\|x)=\frac{1}{1+e^{\theta^Tx}}=1-g(x)$ 
  
  由于$y\in\{0,1\}$，可以写成
  
  $P(y_i\|x)=P(y=1\|x)^{y_i} \cdot P(y=0\|x)^{1-y_i}$
  
  所以**似然函数**是：
  
  $$\prod_{i=1}^mP(y_i=1\|x_i)^{y_i} \cdot P(y_i=0\|x_i)^{1-y_i}$$

对数形式是：

$$
\begin{aligned}
log(\ell(\theta)) &= log(\prod_{i=1}^mP(y_i=1｜x_i)^{y_i} \cdot P(y_i=0｜x_i)^{1-y_i}) \\
&= \sum^m(y_i log(g(x)) + (1-y_i)log(1-g(x)))
\end{aligned}
$$

对数函数并不会影响原函数的凹凸性质，不会改变原函数的极值点。求解最大似然函数等价于求解代价函数$J(\theta)=-log(\ell(\theta))$的最小值。因此定义逻辑斯底回归的代价函数：

$$
cost=J(\theta)=-log(\ell(\theta))＝－\frac{1}{m} \sum^m_{i=1} \lgroup y_i log(g(x)) + (1-y_i)log(1-g(x)) \rgroup
$$

$$
\begin{aligned}
  J(\theta) &= -\frac{1}{m}\sum^m_{i=1}(y_ilog\frac{g(x^i)}{1-g(x^i)}+log(1-g(x^i)) \\
  &= -\frac{1}{m}\sum^m_{i=1}(y_i\theta^Tx^i - log(1+e^{\theta^Tx^i}))
\end{aligned}
$$

为了求$minJ(\theta)​$使用梯度下降法更新$\theta​$：


$$
\begin{aligned}
\frac{\partial J}{\partial \theta_j}&=-\frac{1}{m}\sum_{i=1}^m(y^{(i)}x^{(i)}_j-\frac{x^{(i)}_je^{\theta^Tx^{(i)}}}{1+e^{\theta^Tx^{(i)}}}) \\
&= -\frac{1}{m}\sum_{i=1}^m(y^{(i)}x^{(i)}_j-x^{(i)}_jg(x^{(i)})) \\
&=\frac{1}{m}\sum_{i=1}^m(g(x^{(i)})-y^{(i)})x^{(i)}_j
\end{aligned}
$$

所以通过

$$
\theta_j = \theta_j-\alpha\frac{\partial J}{\partial \theta_j}=\theta_j-\frac{\alpha}{m}\sum_{i=1}^m(g(x^i)-y^i)x_j^i
$$

来更新$\theta_i$，其中$\alpha$是学习率 。

$$g(x)=\frac{e^{\theta^Tx}}{1+e^{\theta^Tx}}$$

随机梯度下降法：

$$\theta_j=\theta_j-\alpha(g(x^i)-y^i)x^i_j$$ 

每次使用一个样本更新$\theta$

​批量随机梯度下降法(Mini Batch Gradient Descent)：

$$\theta_j=\theta_j-\frac{\alpha}{b}\sum_{i=1}^b(g(x^i)-y^i)x^i_j$$


$b$是`mini-batch size`，训练如下图：

![mini-batch](https://user-images.githubusercontent.com/9495054/53283663-949c6900-3784-11e9-9c49-5c3bbafe71a1.png)



[参考吴恩达的机器学习课件](http://www.holehouse.org/mlclass/06_Logistic_Regression.html)

[SGD](http://stats.stackexchange.com/questions/232056/how-could-stochastic-gradient-descent-save-time-comparing-to-standard-gradient-d/232058#232058)

[SGD 正则化](http://stats.stackexchange.com/questions/251982/stochastic-gradient-descent-for-regularized-logistic-regression)



- 正则化

  L1范数是$\sum_{i=1}^n\|\omega_i\|$

  L2范数是$\frac{1}{2}\sum_{i=1}^n\omega_i^2$

### L2正则化

$$J(\theta) = J_0+\frac{\lambda}{2m}\sum_j\theta_j^2=-\frac{1}{m}\sum^m_{i=1}(y_i\theta^Tx^i - log(1+e^{\theta^Tx^i}))+\frac{\lambda}{2m}\sum_j\theta_j^2$$

$J$对$\theta$求导：

$$
\begin{aligned}
\frac{\partial J}{\partial \theta_j}&=\frac{1}{m}\sum_{i=1}^m(g(x)-y)x_i + \frac{\lambda}{m}\theta_j \\
\frac{\partial J}{\partial \theta_0}&=\frac{1}{m}\sum_{i=1}^m(g(x)-y)x_i 
\end{aligned}
$$

其中$j\in\{1,2,3...\}$,$j=0$时$\theta_0$是偏置项。所以：

$$\theta_j = \theta_j-\alpha\frac{\partial J}{\partial \theta_j}=\theta_j-\frac{\alpha}{m}\sum_{i=1}^m(g(x^i)-y^i)x_j^i-\frac{\alpha \lambda}{m}\theta_j$$ 

如果初始$J(\theta)$先不除以$m$,那

$$\frac{\partial J}{\partial \theta_j}=\sum_{i=1}^m(g(x)-y)x_i + \lambda\theta_j$$ 

于是

$$\theta_j = \theta_j-\alpha\sum_{i=1}^m(g(x^i)-y^i)x_j^i-\alpha \lambda\theta_j$$ 

对于随机梯度下降法有

$$\theta_j = \theta_j-\alpha(g(x^i)-y^i)x_j^i-\alpha \lambda\theta_j$$